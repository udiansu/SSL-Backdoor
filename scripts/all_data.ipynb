{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define CIFAR10 classes\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "root_dir=\"/workspace/sync/SSL-Backdoor/data/CIFAR10\"\n",
    "one_percent_train_file = os.path.join(root_dir, \"one_percent_trainset.txt\")\n",
    "ten_percent_train_file = os.path.join(root_dir, \"ten_percent_trainset.txt\")\n",
    "cifar10_train_file = os.path.join(root_dir, \"cifar10_trainset.txt\")\n",
    "cifar10_test_file = os.path.join(root_dir, \"cifar10_testset.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存储 CIFAR10 数据集为 PNG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/pytorch_base/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/miniconda3/envs/pytorch_base/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR10 dataset has been saved as PNG images in separate train and test folders.\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Function to save CIFAR10 dataset as PNG images\n",
    "def save_cifar10_as_png(root_dir='cifar10_png'):\n",
    "    # Create the root directory if it does not exist\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "\n",
    "    # Load CIFAR10 dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    trainset = torchvision.datasets.CIFAR10(root='/workspace/sync/dataset', train=True, download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root='/workspace/sync/dataset', train=False, download=True, transform=transform)\n",
    "\n",
    "    \n",
    "    # Function to save images\n",
    "    def save_images(dataset, dataset_type):\n",
    "        dataset_dir = os.path.join(root_dir, dataset_type)\n",
    "        if not os.path.exists(dataset_dir):\n",
    "            os.makedirs(dataset_dir)\n",
    "        \n",
    "        for i, (image, label) in enumerate(dataset):\n",
    "            label_name = classes[label]\n",
    "            folder_path = os.path.join(dataset_dir, label_name)\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            \n",
    "            # Convert tensor to PIL Image and save\n",
    "            pil_image = transforms.ToPILImage()(image)\n",
    "            file_name = f'{i:05d}.png'\n",
    "            pil_image.save(os.path.join(folder_path, file_name))\n",
    "\n",
    "    # Save training and testing images\n",
    "    save_images(trainset, 'train')\n",
    "    save_images(testset, 'val')\n",
    "\n",
    "    print(\"CIFAR10 dataset has been saved as PNG images in separate train and test folders.\")\n",
    "\n",
    "\n",
    "# Call the function\n",
    "save_cifar10_as_png(root_dir=root_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为 CIFAR10 数据集创建训练配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config files for CIFAR10 dataset have been created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def create_config_files(root_dir):\n",
    "    # Function to get file paths from a directory\n",
    "    def get_file_paths(directory, cls_index):\n",
    "        file_paths = []\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.png'):\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                file_paths.append(f'{file_path} {cls_index}')\n",
    "        return file_paths\n",
    "\n",
    "    # Function to write config file\n",
    "    def write_config_file(file_path, paths):\n",
    "        with open(file_path, 'w') as f:\n",
    "            for path in paths:\n",
    "                f.write(f'{path}\\n')\n",
    "\n",
    "    # Generate file paths for train and test sets\n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_index = classes.index(cls)\n",
    "        train_dir = os.path.join(root_dir, 'train', cls)\n",
    "        test_dir = os.path.join(root_dir, 'val', cls)\n",
    "\n",
    "        train_paths.extend(get_file_paths(train_dir, cls_index))\n",
    "        test_paths.extend(get_file_paths(test_dir, cls_index))\n",
    "\n",
    "    # Write full train and test config files\n",
    "    write_config_file(cifar10_train_file, train_paths)\n",
    "    write_config_file(cifar10_test_file, test_paths)\n",
    "\n",
    "    # Sample for one percent and ten percent train files\n",
    "    one_percent_paths = random.sample(train_paths, int(len(train_paths) * 0.01))\n",
    "    ten_percent_paths = random.sample(train_paths, int(len(train_paths) * 0.1))\n",
    "\n",
    "    # Write sampled config files\n",
    "    write_config_file(one_percent_train_file, one_percent_paths)\n",
    "    write_config_file(ten_percent_train_file, ten_percent_paths)\n",
    "\n",
    "    print(\"Config files for CIFAR10 dataset have been created.\")\n",
    "\n",
    "# Call the function with the specified root directory\n",
    "create_config_files(root_dir=root_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取CIFAR100, 并且为CIFAR100数据集创建训练配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100 dataset has been saved as PNG images.\n",
      "Config files for CIFAR100 dataset have been created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import random\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "def extract_cifar100_tar(tar_path, extract_path):\n",
    "    if not os.path.exists(extract_path):\n",
    "        os.makedirs(extract_path)\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=extract_path)\n",
    "\n",
    "def save_cifar100_as_png(root_dir='/workspace/sync/SSL-Backdoor/data/CIFAR100'):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    trainset = torchvision.datasets.CIFAR100(root=root_dir, train=True, download=False, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR100(root=root_dir, train=False, download=False, transform=transform)\n",
    "    classes = trainset.classes\n",
    "\n",
    "    def save_images(dataset, dataset_type):\n",
    "        dataset_dir = os.path.join(root_dir, dataset_type)\n",
    "        if not os.path.exists(dataset_dir):\n",
    "            os.makedirs(dataset_dir)\n",
    "        for i, (image, label) in enumerate(dataset):\n",
    "            label_name = classes[label]\n",
    "            folder_path = os.path.join(dataset_dir, label_name)\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            pil_image = transforms.ToPILImage()(image)\n",
    "            pil_image.save(os.path.join(folder_path, f'{i:05d}.png'))\n",
    "\n",
    "    save_images(trainset, 'train')\n",
    "    save_images(testset, 'val')\n",
    "    print(\"CIFAR100 dataset has been saved as PNG images.\")\n",
    "\n",
    "def create_config_files(root_dir='/workspace/sync/SSL-Backdoor/data/CIFAR100'):\n",
    "    dataset = torchvision.datasets.CIFAR100(root_dir, train=True, download=False)\n",
    "    classes = dataset.classes\n",
    "\n",
    "    cifar100_train_file = os.path.join(root_dir, 'cifar100_train.txt')\n",
    "    cifar100_test_file = os.path.join(root_dir, 'cifar100_test.txt')\n",
    "    one_percent_train_file = os.path.join(root_dir, 'cifar100_train_1.txt')\n",
    "    ten_percent_train_file = os.path.join(root_dir, 'cifar100_train_10.txt')\n",
    "\n",
    "    def get_file_paths(directory, cls_index):\n",
    "        return [f\"{os.path.join(directory, f)} {cls_index}\" for f in os.listdir(directory) if f.endswith('.png')]\n",
    "\n",
    "    def write_config_file(file_path, paths):\n",
    "        with open(file_path, 'w') as f:\n",
    "            for path in paths:\n",
    "                f.write(f'{path}\\n')\n",
    "\n",
    "    train_paths, test_paths = [], []\n",
    "    for cls in classes:\n",
    "        cls_index = classes.index(cls)\n",
    "        train_dir = os.path.join(root_dir, 'train', cls)\n",
    "        test_dir = os.path.join(root_dir, 'val', cls)\n",
    "        train_paths.extend(get_file_paths(train_dir, cls_index))\n",
    "        test_paths.extend(get_file_paths(test_dir, cls_index))\n",
    "\n",
    "    write_config_file(cifar100_train_file, train_paths)\n",
    "    write_config_file(cifar100_test_file, test_paths)\n",
    "\n",
    "    one_percent_paths = random.sample(train_paths, max(1, int(len(train_paths) * 0.01)))\n",
    "    ten_percent_paths = random.sample(train_paths, max(1, int(len(train_paths) * 0.1)))\n",
    "\n",
    "    write_config_file(one_percent_train_file, one_percent_paths)\n",
    "    write_config_file(ten_percent_train_file, ten_percent_paths)\n",
    "    print(\"Config files for CIFAR100 dataset have been created.\")\n",
    "\n",
    "\n",
    "tar_path = \"/workspace/sync/dataset/cifar-100-python.tar.gz\"\n",
    "extract_path = \"/workspace/sync/SSL-Backdoor/data/CIFAR100\"\n",
    "extract_cifar100_tar(tar_path, extract_path)\n",
    "save_cifar100_as_png(root_dir=extract_path)\n",
    "create_config_files(root_dir=extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为 STL-10 数据集创建训练配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config files for STL10 dataset have been created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define STL10 classes\n",
    "stl10_classes = ('airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck')\n",
    "\n",
    "# Paths for STL10 dataset\n",
    "stl10_root_dir = \"/workspace/sync/SSL-Backdoor/data/STL-10\"\n",
    "stl10_train_file = os.path.join(stl10_root_dir, \"trainset.txt\")\n",
    "stl10_test_file = os.path.join(stl10_root_dir, \"testset.txt\")\n",
    "stl10_one_percent_train_file = os.path.join(stl10_root_dir, \"1percent_trainset.txt\")\n",
    "stl10_ten_percent_train_file = os.path.join(stl10_root_dir, \"10percent_trainset.txt\")\n",
    "stl10_unlabeled_bin_file = os.path.join(stl10_root_dir, \"stl10_binary\", \"unlabeled_X.bin\")\n",
    "stl10_unlabeled_dir = os.path.join(stl10_root_dir, \"unlabeled\")\n",
    "stl10_unlabeled_file = os.path.join(stl10_root_dir, \"unlabeledset.txt\")\n",
    "\n",
    "def create_stl10_config_files(root_dir):\n",
    "    # Function to write config file\n",
    "    def write_config_file(file_path, paths):\n",
    "        with open(file_path, 'w') as f:\n",
    "            for path in paths:\n",
    "                f.write(f'{path.strip()}\\n')\n",
    "\n",
    "    # Read lines directly from trainset.txt\n",
    "    with open(stl10_train_file, 'r') as f:\n",
    "        train_lines = f.readlines()\n",
    "\n",
    "    # Sample for one percent and ten percent train files\n",
    "    one_percent_paths = random.sample(train_lines, int(len(train_lines) * 0.01))\n",
    "    ten_percent_paths = random.sample(train_lines, int(len(train_lines) * 0.1))\n",
    "\n",
    "    # Write sampled config files\n",
    "    write_config_file(stl10_one_percent_train_file, one_percent_paths)\n",
    "    write_config_file(stl10_ten_percent_train_file, ten_percent_paths)\n",
    "\n",
    "    # Create directory for unlabeled images if it doesn't exist\n",
    "    if not os.path.exists(stl10_unlabeled_dir):\n",
    "        os.makedirs(stl10_unlabeled_dir)\n",
    "\n",
    "    # Load unlabeled data from bin file\n",
    "    with open(stl10_unlabeled_bin_file, 'rb') as f:\n",
    "        unlabeled_data = np.fromfile(f, dtype=np.uint8)\n",
    "        unlabeled_data = unlabeled_data.reshape(-1, 3, 96, 96)\n",
    "        unlabeled_data = np.transpose(unlabeled_data, (0, 2, 3, 1))\n",
    "\n",
    "    # Save unlabeled images as PNG and create config file\n",
    "    unlabeled_paths = []\n",
    "    for i, img in enumerate(unlabeled_data):\n",
    "        img_path = os.path.join(stl10_unlabeled_dir, f'unlabeled_{i}.png')\n",
    "        Image.fromarray(img).save(img_path)\n",
    "        unlabeled_paths.append(img_path)\n",
    "\n",
    "    write_config_file(stl10_unlabeled_file, unlabeled_paths)\n",
    "\n",
    "    print(\"Config files for STL10 dataset have been created.\")\n",
    "\n",
    "# Call the function with the specified root directory\n",
    "create_stl10_config_files(root_dir=stl10_root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分别采样 25%、10%、5% 的ImageNet-100数据集用作蒸馏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "data_root = \"/workspace/sync/SSL-Backdoor/data/ImageNet-100\"\n",
    "ImageNet100_train_file = os.path.join(data_root, \"ImageNet100_trainset.txt\")\n",
    "\n",
    "# train_file format\n",
    "# /workspace/sync/SSL-Backdoor/data/ImageNet-100/train/n01558993/n01558993_10224.JPEG 0\n",
    "# /workspace/sync/SSL-Backdoor/data/ImageNet-100/train/n01558993/n01558993_10835.JPEG 0\n",
    "# /workspace/sync/SSL-Backdoor/data/ImageNet-100/train/n01558993/n01558993_10351.JPEG 0\n",
    "\n",
    "\n",
    "# Function to read and sample the dataset\n",
    "def sample_dataset(file_path, sample_fraction):\n",
    "    # Read the dataset\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    # Randomly sample a fraction of the dataset\n",
    "    sample_size = int(len(data) * sample_fraction)\n",
    "    sampled_data = random.sample(data, sample_size)\n",
    "\n",
    "    return sampled_data\n",
    "\n",
    "# Sampling 25% and 5% of the data\n",
    "sampled_25_percent = sample_dataset(ImageNet100_train_file, 0.25)\n",
    "sampled_5_percent = sample_dataset(ImageNet100_train_file, 0.05)\n",
    "\n",
    "# Create new configuration files for the sampled datasets\n",
    "sampled_25_file_path = os.path.join(data_root, \"25percent_trainset.txt\")\n",
    "sampled_5_file_path = os.path.join(data_root, \"5percent_trainset.txt\")\n",
    "\n",
    "with open(sampled_25_file_path, 'w') as file:\n",
    "    file.writelines(sampled_25_percent)\n",
    "\n",
    "with open(sampled_5_file_path, 'w') as file:\n",
    "    file.writelines(sampled_5_percent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采样另外的ImageNet类别模拟 label shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# 文件路径\n",
    "existing_classes_file = \"/workspace/sync/SSL-Backdoor/poison-generation/scripts/imagenet100_classes.txt\"\n",
    "imagenet_1k_dir = \"/workspace/sync/imagenet-1k/train\"\n",
    "new_classes_file = \"/workspace/sync/SSL-Backdoor/poison-generation/scripts/new_n03085013_imagenet100_classes.txt\"\n",
    "\n",
    "# 读取现有的Imagenet100类别\n",
    "with open(existing_classes_file, 'r') as file:\n",
    "    existing_classes = set(file.read().splitlines())\n",
    "\n",
    "# 获取ImageNet训练集的所有类别\n",
    "all_classes = set(os.listdir(imagenet_1k_dir))\n",
    "print(len(all_classes))\n",
    "# 筛选出未包含在现有类别中的类别\n",
    "new_classes_candidates = list(all_classes - existing_classes)\n",
    "print(len(new_classes_candidates))\n",
    "# 从这些类别中随机选择99个\n",
    "selected_classes = random.sample(new_classes_candidates, 99)\n",
    "\n",
    "# 加上类别n07831146\n",
    "selected_classes.append(\"n03085013\")\n",
    "\n",
    "# 写入新的配置文件\n",
    "with open(new_classes_file, 'w') as file:\n",
    "    for cls in selected_classes:\n",
    "        file.write(cls + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从新的transferring_ImageNet-100中采样1%和10%的数据用作linear probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def sample_images_from_folder(folder_path, sample_ratio):\n",
    "    \"\"\"\n",
    "    Sample images from a folder at a specified ratio.\n",
    "    \"\"\"\n",
    "    all_images = os.listdir(folder_path)\n",
    "    sampled_images = random.sample(all_images, int(len(all_images) * sample_ratio))\n",
    "    return sampled_images\n",
    "def create_config_file_for_training_and_validation_sorted(training_folder, validation_folder, output_file_train_10, output_file_train_1, output_file_val):\n",
    "    \"\"\"\n",
    "    Create configuration files for training data with sampled images and for all validation images, sorted by class names.\n",
    "    \"\"\"\n",
    "    # Retrieve and sort class folders\n",
    "    class_folders = sorted([f for f in os.scandir(training_folder) if f.is_dir()], key=lambda x: x.name)\n",
    "    class_labels = {os.path.basename(f.path): i for i, f in enumerate(class_folders)}\n",
    "\n",
    "    # Create config files for training data with sorted class names\n",
    "    with open(output_file_train_10, 'w') as file_10, open(output_file_train_1, 'w') as file_1:\n",
    "        for folder in class_folders:\n",
    "            class_label = class_labels[os.path.basename(folder.path)]\n",
    "            sampled_images = sample_images_from_folder(folder.path, 0.10)\n",
    "            for image in sampled_images:\n",
    "                file_10.write(f\"{folder.path}/{image} {class_label}\\n\")\n",
    "\n",
    "            sampled_images = sample_images_from_folder(folder.path, 0.01)\n",
    "            for image in sampled_images:\n",
    "                file_1.write(f\"{folder.path}/{image} {class_label}\\n\")\n",
    "\n",
    "    # Create config file for validation data with sorted class names\n",
    "    with open(output_file_val, 'w') as file_val:\n",
    "        for folder in class_folders:\n",
    "            class_label = class_labels[os.path.basename(folder.path)]\n",
    "            val_folder_path = os.path.join(validation_folder, os.path.basename(folder.path))\n",
    "            val_images = os.listdir(val_folder_path)\n",
    "            for image in val_images:\n",
    "                file_val.write(f\"{val_folder_path}/{image} {class_label}\\n\")\n",
    "\n",
    "# Paths\n",
    "training_folder_path = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/train\"\n",
    "validation_folder_path = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/val\"\n",
    "output_file_train_10_percent = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/10percent_trainset.txt\"\n",
    "output_file_train_1_percent = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/1percent_trainset.txt\"\n",
    "output_file_validation = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/ImageNet100_valset.txt\"\n",
    "\n",
    "# Call function\n",
    "create_config_file_for_training_and_validation_sorted(training_folder_path, validation_folder_path, output_file_train_10_percent, output_file_train_1_percent, output_file_validation)\n",
    "\n",
    "# Note: The class folders are sorted by their names. This code still assumes the same class folders exist in both training and validation directories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从ImageNet100构造数据集配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def sample_images_from_folder(folder_path, sample_ratio):\n",
    "    \"\"\"\n",
    "    Sample images from a folder at a specified ratio.\n",
    "    \"\"\"\n",
    "    all_images = os.listdir(folder_path)\n",
    "    sampled_images = random.sample(all_images, int(len(all_images) * sample_ratio))\n",
    "    return sampled_images\n",
    "\n",
    "training_folder_path = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/train\"\n",
    "validation_folder_path = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/val\"\n",
    "output_file_train_10_percent = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/10percent_trainset.txt\"\n",
    "output_file_train_1_percent = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/1percent_trainset.txt\"\n",
    "output_file_validation = \"/workspace/sync/SSL-Backdoor/data/transferring_ImageNet-100_n03085013/ImageNet100_valset.txt\"\n",
    "\n",
    "# Call function\n",
    "create_config_file_for_training_and_validation_sorted(training_folder_path, validation_folder_path, output_file_train_10_percent, output_file_train_1_percent, output_file_validation)\n",
    "\n",
    "# Note: The class folders are sorted by their names. This code still assumes the same class folders exist in both training and validation directories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从ImageNet100构造数据集配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def sample_images_from_folder(folder_path, sample_ratio):\n",
    "    \"\"\"\n",
    "    Sample images from a folder at a specified ratio.\n",
    "    \"\"\"\n",
    "    all_images = os.listdir(folder_path)\n",
    "    sampled_images = random.sample(all_images, int(len(all_images) * sample_ratio))\n",
    "    return sampled_images\n",
    "\n",
    "def create_config_file_for_training_and_validation_sorted(training_folder, validation_folder, output_file_train_all, output_file_train_10, output_file_train_1, output_file_val):\n",
    "    \"\"\"\n",
    "    Create configuration files for training data with all images, sampled images, and for all validation images, sorted by class names.\n",
    "    \"\"\"\n",
    "    # Retrieve and sort class folders\n",
    "    class_folders = sorted([f for f in os.scandir(training_folder) if f.is_dir()], key=lambda x: x.name)\n",
    "    class_labels = {os.path.basename(f.path): i for i, f in enumerate(class_folders)}\n",
    "\n",
    "    # Create config files for training data with sorted class names\n",
    "    with open(output_file_train_all, 'w') as file_all, open(output_file_train_10, 'w') as file_10, open(output_file_train_1, 'w') as file_1:\n",
    "        for folder in class_folders:\n",
    "            class_label = class_labels[os.path.basename(folder.path)]\n",
    "            all_images = os.listdir(folder.path)\n",
    "            for image in all_images:\n",
    "                file_all.write(f\"{folder.path}/{image} {class_label}\\n\")\n",
    "\n",
    "            sampled_images = sample_images_from_folder(folder.path, 0.10)\n",
    "            for image in sampled_images:\n",
    "                file_10.write(f\"{folder.path}/{image} {class_label}\\n\")\n",
    "\n",
    "            sampled_images = sample_images_from_folder(folder.path, 0.01)\n",
    "            for image in sampled_images:\n",
    "                file_1.write(f\"{folder.path}/{image} {class_label}\\n\")\n",
    "\n",
    "    # Create config file for validation data with sorted class names\n",
    "    with open(output_file_val, 'w') as file_val:\n",
    "        for folder in class_folders:\n",
    "            class_label = class_labels[os.path.basename(folder.path)]\n",
    "            val_folder_path = os.path.join(validation_folder, os.path.basename(folder.path))\n",
    "            val_images = os.listdir(val_folder_path)\n",
    "            for image in val_images:\n",
    "                file_val.write(f\"{val_folder_path}/{image} {class_label}\\n\")\n",
    "\n",
    "# Paths\n",
    "training_folder_path = \"/workspace/sync/SSL-Backdoor/data/ImageNet-100-A/train\"\n",
    "validation_folder_path = \"/workspace/sync/SSL-Backdoor/data/ImageNet-100-A/val\"\n",
    "output_file_train_all_images = \"/workspace/sync/SSL-Backdoor/data/ImageNet-100-A/trainset.txt\"\n",
    "output_file_train_10_percent = \"/workspace/sync/SSL-Backdoor/data/ImageNet-100-A/10percent_trainset.txt\"\n",
    "output_file_train_1_percent = \"/workspace/sync/SSL-Backdoor/data/ImageNet-100-A/1percent_trainset.txt\"\n",
    "output_file_validation = \"/workspace/sync/SSL-Backdoor/data/ImageNet-100-A/valset.txt\"\n",
    "\n",
    "# Call function\n",
    "create_config_file_for_training_and_validation_sorted(training_folder_path, validation_folder_path, output_file_train_all_images, output_file_train_10_percent, output_file_train_1_percent, output_file_validation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
